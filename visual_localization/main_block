目标：通过视觉、IMU、GPS、轮速计组合，完成高精度的导航定位

Block 1:
系统初始化：
1.1 摄像机参数、噪声方差（图像噪声、IMU噪声、IMU的bias）、初始的IMU协方差、IMU和摄像机的外参数、IMU和摄像机的时间偏移量

1.2 连续相机的SFM优化与IMU融合，确定VIO初始位姿；

1.3 如果有GPS观测，将GPS观测与VIO初始化位姿融合，确定全局视觉组合定位位姿；
    参考：http://www.ece.ust.hk/~eeshaojie/iros2017tong.pdf

1.4 MSCKF配置参数：状态向量里滑动窗口大小的范围、空间点三角化误差阈值、是否做零空间矩阵构造和QR分解

1.5 构造MSCKF状态向量
    IMU状态（位姿态、方差等）、滑动窗口内的Camera位姿、鲁棒的视觉特征、GPS状态；

Block 2：
2.1 读取IMU数据，估计新的MSCKF状态变量和对应的协方差矩阵
    龙哥库塔法或解析法；
    解析法： http://udel.edu/~ghuang/papers/tr_cpi.pdf

Block 3：
3.特征提取及特征跟踪
3.1 MSCKF状态向量中增加当前帧的摄像机位姿；若位姿数大于滑动窗口大小的范围，去除状态变量中最早的视图对应的摄像机位姿

    参考： Stochastic Cloning: A generalized framework for processing relative state measurements

3.2提取图像特征并匹配，去除外点。

3.3 处理所有提取的特征。判断当前特征是否是之前视图中已经观察到的特征

是：

3.3.1 如果当前帧还可以观测到该特征，则加入该特征的track列表

3.3.2 如果当前帧观测不到该特征(Out_of_View)，将该特征的track加入到featureTracksToResidualize，用于更新MSCKF的状态变量

否；

Block 4：

4.1 给该特征分配新的featureID，并加入到当前视图可观测特征的集合

4.2 循环遍历featureTracksToResidualize中的track，用于更新MSCKF的状态变量

4.2.1 计算每个track对应的三维空间点坐标(利用第一幅视图和最后一幅视图计算两视图三角化，使用逆深度参数化和高斯牛顿优化求解)，若三角化误差小于设置的阈值，则加入map集合

4.2.2 计算视觉观测(即图像特征)的估计残差，并计算图像特征的雅克比矩阵

4.2.3 计算图像特征雅克比矩阵的左零空间矩阵和QR分解，构造新的雅克比矩阵

4.3 计算新的MSCKF状态向量的协方差矩阵

4.3.1 计算Kalman增益

4.3.2 状态矫正

4.3.3 计算新的协方差矩阵

3.6 状态变量管理

3.6.1 查找所有无feature track可见的视图集合deleteIdx

3.6.2 将deleteIdx中的视图对应的MSCKF中的状态去除掉

3.6.3 绘制运动轨迹

补充：

1. IMU读取数据时尽量接近当前摄像机图像获取的时间，最好先离线标定IMU的bias

2. 离线标定好摄像机内参数，必要的话把畸变因子也标定出来。算法运行时，利用摄像机内参数将图像特征归一化到摄像机坐标系。

3. 图像特征选择ORB之类的(提取和匹配速度快且具有旋转尺度不变性)，特征匹配时使用快速鲁棒的方法去除外点

4. 若当前视角下场景纹理不丰富，提取的特征较少，则调用另一个函数，只利用IMU的读数做EKF更新

5. 根据摄像机能观察到的track个数，摄像机之间的base长度、角度，确定关键帧，并构造摄像机视图的graph，根据摄像机之间的关系，利用g2o等工具优化摄像机轨迹

6. 可以利用并行线程，实时构建地图，并构造DBOW，用于回环检测和重定位

